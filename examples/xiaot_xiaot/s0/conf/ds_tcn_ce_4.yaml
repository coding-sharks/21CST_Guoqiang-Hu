dataset_conf:
    filter_conf:
        max_length: 2048
        min_length: 0
    resample_conf:
        resample_rate: 16000
    speed_perturb: true    # false
    feature_extraction_conf:
        feature_type: 'fbank'
        num_mel_bins: 80
        frame_shift: 10
        frame_length: 25
        dither: 1.0
    spec_aug: true
    spec_aug_conf:
        num_t_mask: 1
        num_f_mask: 1
        max_t: 20
        max_f: 10
    shuffle: true
    shuffle_conf:
        shuffle_size: 1500
    batch_conf:
        batch_size: 128

model:
    hidden_dim: 256
    preprocessing:
        type: linear
    backbone:
        type: tcn
        ds: true
        num_layers: 4
        kernel_size: 8
        dropout: 0.1
    classifier: # 
        type: global
        dropout: 0.45

optim: adam
optim_conf:
    lr: 0.001
    weight_decay: 0.0001

training_config:
    grad_clip: 5
    max_epoch: 80
    log_interval: 10
    criterion: ce # max_pooling

# 这个模型相比于global_3，提高了dropout，0.35->0.45
# 看看最终效果如何
# 我看ACC曲线，效果比global_3差，看来dropout设置太高了