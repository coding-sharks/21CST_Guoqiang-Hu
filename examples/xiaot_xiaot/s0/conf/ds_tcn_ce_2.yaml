dataset_conf:
    filter_conf:
        max_length: 2048
        min_length: 0
    resample_conf:
        resample_rate: 16000
    speed_perturb: true    # false
    feature_extraction_conf:
        feature_type: 'fbank'
        num_mel_bins: 40
        frame_shift: 10
        frame_length: 25
        dither: 1.0
    spec_aug: true
    spec_aug_conf:
        num_t_mask: 1
        num_f_mask: 1
        max_t: 20
        max_f: 10
    shuffle: true
    shuffle_conf:
        shuffle_size: 1500
    batch_conf:
        batch_size: 64

model:
    hidden_dim: 256
    preprocessing:
        type: linear
    backbone:
        type: tcn
        ds: true
        num_layers: 4
        kernel_size: 8
        dropout: 0.1
    classifier: # 
        type: global
        dropout: 0.3

optim: adam
optim_conf:
    lr: 0.001
    weight_decay: 0.0001

training_config:
    grad_clip: 5
    max_epoch: 20
    log_interval: 10
    criterion: ce # max_pooling

# 这个模型配置的目的是为了测试，当提高dropout的值后，过拟合的情况是否有所改善
# 所以仅采用了20的max_epoch

# 结果：模型在测试集上的ACC相比于之前，没有提高，因为到20epoch的时候还没稳定
# 所以在global_3继续跑吧